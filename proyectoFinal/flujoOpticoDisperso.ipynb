{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chj06\\AppData\\Local\\Temp\\ipykernel_4416\\2232351365.py:177: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  freeman_data = np.array(freeman_data)\n",
      "c:\\Users\\chj06\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Capturar video\n",
    "cap = cv2.VideoCapture('vtest.avi')\n",
    "\n",
    "# Parámetros para el flujo óptico\n",
    "lk_params = dict(winSize=(15, 15),\n",
    "                 maxLevel=2,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Inicializar el modelo MOG2 para la sustracción de fondo\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Leer el primer frame\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detección de características en el primer frame\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    "\n",
    "# Crear una máscara para dibujar los puntos\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "frame_count = 0\n",
    "folder_name = \"FOD_vtest\"\n",
    "if os.path.exists(folder_name):\n",
    "    shutil.rmtree(folder_name)  # Eliminar la carpeta y su contenido\n",
    "os.makedirs(folder_name)\n",
    "\n",
    "freeman_data = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Aplicar sustracción de fondo usando MOG2\n",
    "    fgmask = fgbg.apply(frame)\n",
    "\n",
    "    # Aplicar umbral para la segmentación\n",
    "    threshold = 50  # Ajusta este valor según tus necesidades\n",
    "    _, thresh = cv2.threshold(fgmask, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Encontrar contornos en la máscara segmentada\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filtrar contornos por área\n",
    "    min_contour_area = 100  # Ajusta este valor según tus necesidades\n",
    "    filtered_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_contour_area]\n",
    "\n",
    "    # Crear una nueva máscara para contornos filtrados\n",
    "    mask_filtered_contours = np.zeros_like(frame)\n",
    "\n",
    "    # Dibujar contornos filtrados en la nueva máscara\n",
    "    cv2.drawContours(mask_filtered_contours, filtered_contours, -1, (255, 255, 255), thickness=cv2.FILLED)\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    if frame_count % 5 == 0:\n",
    "        name = os.path.join(folder_name, f'frame{frame_count}.jpg')\n",
    "        cv2.imwrite(name, mask_filtered_contours)\n",
    "\n",
    "    if len(mask_filtered_contours.shape) > 2:\n",
    "        mask_filtered_contours = cv2.cvtColor(mask_filtered_contours, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Cambiar el tipo de datos a CV_8UC1\n",
    "    mask_filtered_contours = cv2.convertScaleAbs(mask_filtered_contours)\n",
    "\n",
    "    # Aplicar umbral adaptativo a la máscara filtrada\n",
    "    adaptive_thresh = cv2.adaptiveThreshold(mask_filtered_contours, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    # Guardar la imagen del umbral adaptativo\n",
    "    if frame_count % 5 == 0:\n",
    "        adaptive_thresh_filename = os.path.join(folder_name, f'adaptive_thresh_{frame_count}.jpg')\n",
    "        cv2.imwrite(adaptive_thresh_filename, adaptive_thresh)\n",
    "\n",
    "    # Encontrar contornos en la máscara\n",
    "    contours, _ = cv2.findContours(adaptive_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Calcular el área promedio de los contornos\n",
    "    average_contour_area = sum(cv2.contourArea(cnt) for cnt in contours) / len(contours)\n",
    "\n",
    "    # Obtener la cadena de Freeman\n",
    "    freeman_chain = []\n",
    "    if len(contours) > 0:\n",
    "        # Aproximar el contorno usando Douglas-Peucker\n",
    "        epsilon = 0.02 * cv2.arcLength(contours[0], True)\n",
    "        approx_contour = cv2.approxPolyDP(contours[0], epsilon, True)\n",
    "\n",
    "        for i in range(1, len(approx_contour)):\n",
    "            x_diff = approx_contour[i][0][0] - approx_contour[i - 1][0][0]\n",
    "            y_diff = approx_contour[i][0][1] - approx_contour[i - 1][0][1]\n",
    "\n",
    "            # Asignar dirección de Freeman (0 a 7)\n",
    "            freeman_direction = (y_diff + 1) * 3 + (x_diff + 1)\n",
    "            freeman_chain.append(freeman_direction)\n",
    "\n",
    "        # Dibujar el contorno aproximado en la imagen de umbralización\n",
    "        cv2.drawContours(adaptive_thresh, [approx_contour], 0, (255, 0, 0), 2)\n",
    "\n",
    "        # Dibujar la cadena de Freeman en la imagen de umbralización\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        for i, direction in enumerate(freeman_chain):\n",
    "            cv2.putText(adaptive_thresh, str(direction), (approx_contour[i][0][0], approx_contour[i][0][1]),\n",
    "                        font, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "        if frame_count % 5 == 0:\n",
    "            freeman_filename = os.path.join(folder_name, f'freeman_{frame_count}.jpg')\n",
    "            cv2.imwrite(freeman_filename, adaptive_thresh)\n",
    "\n",
    "    # Almacena los puntos de la cadena de Freeman\n",
    "    freeman_data.append(freeman_chain)\n",
    "\n",
    "    \n",
    "    # Dibujar solo los contornos filtrados\n",
    "    frame_with_filtered_contours = frame.copy()\n",
    "    cv2.drawContours(frame_with_filtered_contours, filtered_contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    # Calcular flujo óptico\n",
    "    p1, _, _ = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "    # Seleccionar puntos válidos\n",
    "    p1_valid = p1[~np.isnan(p1).any(axis=2)]\n",
    "    good_new = p1_valid.reshape(-1, 1, 2)\n",
    "\n",
    "    # Ensure p0 has the same shape as good_new\n",
    "    p0 = p0[:good_new.shape[0], :, :]\n",
    "\n",
    "    # Seleccionar puntos antiguos correspondientes a los puntos válidos\n",
    "    good_old = p0[~np.isnan(p1).any(axis=2)]\n",
    "\n",
    "    # Dibujar líneas y puntos en el frame\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "        mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), (0, 255, 0), 2)\n",
    "        frame = cv2.circle(frame, (int(a), int(b)), 5, (0, 255, 0), -1)\n",
    "\n",
    "    # Calcular el flujo óptico entre los puntos anteriores y nuevos\n",
    "    flow = p1 - p0\n",
    "\n",
    "    # Calcular la magnitud del flujo óptico\n",
    "    magnitude = np.sqrt(np.sum(flow**2, axis=2))\n",
    "\n",
    "    # Aplicar umbral para la segmentación\n",
    "    threshold_optical_flow = 1.0  # Ajusta este valor según tus necesidades\n",
    "    mask_segmentation_optical_flow = (magnitude > threshold_optical_flow).astype(np.uint8) * 255\n",
    "\n",
    "    mask_segmentation_resized = cv2.resize(mask_segmentation_optical_flow, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "    # Mostrar las imágenes (opcional, puedes comentar estas líneas si no las necesitas)\n",
    "    cv2.imshow('Original Frame', frame)\n",
    "    cv2.imshow('Moving Objects with Contours', frame_with_filtered_contours)\n",
    "    cv2.imshow('Mask with Filtered Contours', mask_filtered_contours)\n",
    "    cv2.imshow('Adaptive Threshold', adaptive_thresh)\n",
    "\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # Actualizar el marco anterior\n",
    "    old_gray = frame_gray.copy()\n",
    "\n",
    "# Liberar recursos\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "\n",
    "# Aplicar k-Means a los datos de la cadena de Freeman\n",
    "freeman_data = np.array(freeman_data)\n",
    "freeman_data_flat = [item for sublist in freeman_data for item in sublist]  # Aplanar la lista de listas\n",
    "freeman_data_flat = np.array(freeman_data_flat).reshape(-1, 1)\n",
    "freeman_data_scaled = StandardScaler().fit_transform(freeman_data_flat)\n",
    "\n",
    "k = 3  # Número de clusters deseado\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "clusters = kmeans.fit_predict(freeman_data_scaled)\n",
    "\n",
    "colors = [(0, 0, 255), (0, 255, 0), (255, 0, 0)]  # Rojo, verde, azul\n",
    "cluster_colors = [colors[label] for label in clusters]\n",
    "\n",
    "# Supongamos que 'adaptive_thresh' es tu imagen de umbralización\n",
    "result_image = cv2.cvtColor(adaptive_thresh, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "for i, contour in enumerate(filtered_contours):\n",
    "    for point in contour:\n",
    "        x, y = point[0]\n",
    "        color = cluster_colors[i]\n",
    "        cv2.circle(result_image, (int(x), int(y)), 3, color, -1)\n",
    "\n",
    "        cv2.circle(result_image, (x, y), 3, color, -1)\n",
    "\n",
    "for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "    a, b = new.ravel()\n",
    "    c, d = old.ravel()\n",
    "    color = cluster_colors[i]\n",
    "    cv2.circle(result_image, (int(a), int(b)), 3, color, -1)\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow('Clustered Image', result_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar imágenes usando Matplotlib\n",
    "image_files = sorted([os.path.join(folder_name, f) for f in os.listdir(folder_name) if f.endswith('.jpg')])\n",
    "\n",
    "for image_file in image_files:\n",
    "    img = cv2.imread(image_file)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
